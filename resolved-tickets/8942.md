
# Question on the Proper Memory Size for pgsql DB <!-- Ticket Title  Hint: include keywords to make it searchable -->

- Zendesk Link: [#8942](https://sourcegraph.zendesk.com/agent/tickets/8942)
- Application engineer: Michael Bali
- Customer: Coupang <!-- Redact if this contains personally identifying information -->
- Date: June 13, 2022

<!-- Data populated from integration, speak to Ben Gordon or Michael Bali if not working -->
<!-- During Internal team trial, fill missing data manually (we are waiting for all data to sync) -->

## Technical Environment
- Version: ​3.39.1
- Deployment: Helm
- External Services: GitHub
- Auth Providers: github 


## Links
<!-- Data for application engineer manual entry -->
- Slack Links: https://sourcegraph.slack.com/archives/C02NFUV7V9A/p1655170902182859
- GitHub Issue Link: N/A
- Doc Update Link: N/A

## Summary
### Customer Question
I have a question for sourcegraph pgsql database’s proper memory size.
Currently we setup external pgsql database on aws Aurora PostgreSQL.
this db instance type is db.r6g.large (vCPU: 2core, memory: 16GB).
When I first built it, it had 3.5 GB of free memory. but now it have only 0.8 GB.
So I wonder what affects the size of the memory for pgsql database ? and should I scale up db instance type?

### Application Engineer Answer
The main Postgres DB (pgsql) has a higher number of CPU cores than other instances, which suggests that most of the operations are READ operations that take more processing power than the other DB instances. My recommendation based off previous customer experience is to enable auto-scaling for DB disks since you are using a cloud provider.

### Relevant Docs Pages Used/Created

<!-- Once complete, upload a copy to https://github.com/sourcegraph/support-tools-internal/tree/main/resolved-tickets as a .md file -->
<!-- Name the file 8942.md -->
