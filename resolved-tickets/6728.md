# Timeouts across the board; overloaded CPU <!-- Ticket Title  Hint: include keywords to make it searchable -->

- Zendesk Link: [#6728](https://sourcegraph.zendesk.com/agent/tickets/6728)
- Application engineer: Jason Harris
- Customer: Netflix <!-- Redact if this contains personally identifying information -->
- Date: Mar 9

<!-- Data populated from integration, speak to Ben Gordon or Michael Bali if not working -->
<!-- During Internal team trial, fill missing data manually (we are waiting for all data to sync) -->

## Technical Environment
- Version: 3.37.0​
- Deployment: pure-docker
- External Services: BITBUCKETSERVER
- Auth Providers: http-header


## Links
<!-- Data for application engineer manual entry -->
- Slack Links: https://netflix.slack.com/archives/CHKL4G5PG/p1646848114303209 and https://netflix.slack.com/archives/CHKL4G5PG/p1646850507952629 
- GitHub Issue Link: https://github.com/sourcegraph/customer/issues/754  
- Doc Update Link:

## Summary
### Description of Customer Issue
Timeouts are occurring across the board, ultimately resulting in needing to shut down the instance to restart it. Timeouts started slowly, then increased rapidly, until the instance was not useable.

### Troubleshooting Steps
Got on a call with Ricardo. Here's the summary: 

- Netflix restarted their instance and it appears to be healthy now.

- There were some logs that caused concern. They saw some code monitors take 20s+ to run a GraphQL query. The CodeMonitors in question performed diff-level queries against a large monorepo.

- Zoekt was quite active for a brief period of time that caused some more alerts to fire regarding CPU utilization. I think this is largely expected for a single-instance deployment with a large repo & usage footprint.

- The Worker Grafana dashboard did not have any data. We believe this is due to an out-of-date Prometheus configuration. This is causing concern as alerts are showing in Granfana indicating the workers were not running. We added debug logging to verify the workers were running.

- We still want to do a little bit of follow-up work regarding the Discover: failed to connect to host=codeinsights-DB user=postgres database=postgres: server error (FATAL: sorry, too many clients already (SQLSTATE 53300))" error message. 

### Resolution
This ultimately ended up being a Prometheus config issue. We updated the Prometheus config and all the deployment is now healthy.

### Relevant Docs Pages Used/Created

### Relevant Error / Logs
<!-- Please redact keys, tokens, and personal identifying information -->


<!-- Once complete, upload a copy to https://github.com/sourcegraph/support-tools-internal/tree/main/resolved-tickets as a .md file -->
<!-- Name the file 6728.md -->
