
# Symbol container growing past 100gb <!-- Ticket Title  Hint: include keywords to make it searchable -->

- Zendesk Link: [#7514](https://sourcegraph.zendesk.com/agent/tickets/7514)
- Application engineer: Michael Bali
- Customer: Databricks <!-- Redact if this contains personally identifying information -->
- Date: Apr 6

<!-- Data populated from integration, speak to Ben Gordon or Michael Bali if not working -->
<!-- During Internal team trial, fill missing data manually (we are waiting for all data to sync) -->

## Technical Environment
- Version: ​N/A
- Deployment: N/A
- External Services: N/A
- Auth Providers: N/A


## Links
<!-- Data for application engineer manual entry -->
- Slack Links: https://sourcegraph.slack.com/archives/C02UM8A9M2R/p1649292584874699
- GitHub Issue Link: N/A
- Doc Update Link: N/A

## Summary
### Description of Customer Issue
Symbol container growing past 100gb which is strange

### Troubleshooting Steps
- Did a preliminary investigation, I understand this is an issue that was discovered in the past to be a bug and was fixed in version 3.37. I can see on my end you are on version 3.38, can you double confirm that for me?
- Asked for logs related to the symbols container
- Requested fo screenshot of the https://sourcegraph.example.com/-/debug/grafana/d/symbols/symbols and include the "janitor" section?
- Could you also send us the output of `find /mount/symbols-0/cache -type f | xargs ls -lhrt` to see if there are non-DB files piling up?
- Did you notice it respecting the 100GB limit previously, and now it's not?Did you set `SYMBOLS_CACHE_SIZE_MB`? 
- noticing a discrepancy in reported disk usage:
- `du -sch` shows 142GB
- Grafana shows ~50GB
- This could be caused by a build-up of partial files in the cache. Could you run `find /mnt/docker-data/volumes/docker-compose_symbols-0/cache -type f | xargs ls -lhrt` to check?
- Seems as if everything changed from writing to symbols to enterprise-symbols, that could be the problem.





### Resolution
I don't think the total disk usage will exceed 200GB (100GB for each of the dirs `symbols` and `enterprise-symbols`), but you can delete the old `symbols` dir to clean up that disk space.


### Relevant Docs Pages Used/Created

### Relevant Error / Logs
<!-- Please redact keys, tokens, and personal identifying information -->
```
t=2022-04-01T01:26:40+0000 lvl=eror msg="diskcache.Cached Fetch" error="context canceled" count=1.000 elapsed=19.895 component=symbols
t=2022-04-01T01:26:40+0000 lvl=eror msg=codeintel.symbols.api.Search error="databaseWriter.GetOrCreateDatabaseFile: context canceled" count=1.000 elapsed=19.904 parseAmount=partial-parse repo=databricks/runtime commitID=3427c4a9c6bc1ada2041f958f3a251e103c59336 query=^getOrElse$ isRegExp=true isCaseSensitive=true numIncludePatterns=1 includePatterns=\\.(sbt|sc|scala)$ excludePattern= first=31 
```



```-rw------- 1 root root 561M Mar 23 02:51 /mnt/docker-data/volumes/docker-compose_symbols-0/_data/symbols/586cc9f0adfb8718c910659863530405c0dc843c8dea4ef2c9ac010c553c0a1b/e4b1a2ef2b71b5b4d1c38664046aa4ed0ca932bf261867d0a4cc1f7fdc4a0307.zip
-rw------- 1 root root 390M Mar 23 03:24 /mnt/docker-data/volumes/docker-compose_symbols-0/_data/enterprise-symbols/ef2d127de37b942baad06145e54b0c619a1f22327b2ebbcfbec78f5564afe39d/586cc9f0adfb8718c910659863530405c0dc843c8dea4ef2c9ac010c553c0a1b/accb2821d23149974830738b7548dc2d83822f2fc70f171e578c6183dd16faa8.zip```
<!-- Once complete, upload a copy to https://github.com/sourcegraph/support-tools-internal/tree/main/resolved-tickets as a .md file -->
<!-- Name the file 7514.md -->
