
# Slow Performance for Batch Changes <!-- Ticket Title  Hint: include keywords to make it searchable -->

- Zendesk Link: [#5413](https://sourcegraph.zendesk.com/agent/tickets/5413)
- Application engineer: Gabe Torres
- Customer: Reddit <!-- Redact if this contains personally identifying information -->
- Date: Jan 5

<!-- Data populated from integration, speak to Ben Gordon or Michael Bali if not working -->
<!-- During Internal team trial, fill missing data manually (we are waiting for all data to sync) -->

## Technical Environment
- Version: 3.34.2​
- Deployment: kubernetes
- External Services: GITHUB
- Auth Providers: builtin,github


## Links
<!-- Data for application engineer manual entry -->
- Slack Links: https://sourcegraph.slack.com/archives/C02BJ8T258D/p1641420075234800 
- GitHub Issue Link: https://github.com/sourcegraph/customer/issues/616 
- Doc Update Link: 

## Summary
### Customer Question
So, I tried running src batch preview on a beefy VM today. It took 11 minutes with 10 works and 10 minutes with 50 workers. From watching the output, it really looks like there’s some serialization going on or something that is preventing it from getting a boost from added concurrency. Not sure if this is really actionable, but I wanted to mention it.
I am talking about the serialized production of the batch change using src batch preview — it downloads a tarball and uploads patches, but those aren’t the parts that I am concerned about. It’s the part where it is freewheeling locally running a bunch of docker containers to execute the change. The 'executing steps' part should be completely independent for one repo vs another, so increasing the number of workers by a factor of 5x should, naively at least, result in increased parallelism if the host has enough resources.

### Application Engineer Answer
I have some possible scenarios that could be causing the batch change to execute at about the same length of time even with more workers.
- There could be one (or a few) repos that take way longer than others and in the end, many workers are just idle
- There could be IO throttling, which is a thing we commonly see on executors for SSBC. Cloning repos, creating a git repo out of the archive and such are very disk-intensive operations, and that won’t get faster by increasing the parallelism.
- A Sourcegraph service src is talking to is limited in either IO, CPU or memory - likely gitserver if that’s the case.

It’s hard to pin point what is happening but this is an area we’re working on improving visibility and debug-ability around with SSBC (specifically, timing each step of the process and providing more logging around what’s happening there).


<!-- Once complete, upload a copy to https://github.com/sourcegraph/support-tools-internal/tree/main/resolved-tickets as a .md file -->
<!-- Name the file 5413.md -->
