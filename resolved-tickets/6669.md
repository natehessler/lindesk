
# New Slack message in support-mercadolibre: unhealthy frontend, gitserver worker and symbols stuck in crash loop, RBAC issue <!-- Ticket Title  Hint: include keywords to make it searchable -->

- Zendesk Link: [#6669](https://sourcegraph.zendesk.com/agent/tickets/6669)
- Application engineer: Riana Shahid
- Customer: MercadoLibre <!-- Redact if this contains personally identifying information -->
- Date: Mar 7

<!-- Data populated from integration, speak to Ben Gordon or Michael Bali if not working -->
<!-- During Internal team trial, fill missing data manually (we are waiting for all data to sync) -->

## Technical Environment
- Version: 3.29.1​
- Deployment: kubernetes
- External Services: GITHUB
- Auth Providers: builtin


## Links
<!-- Data for application engineer manual entry -->
- Slack Links: https://sourcegraph.slack.com/archives/C021PRG65DH/p1646664618402009
- GitHub Issue Link: https://github.com/sourcegraph/customer/issues/752
- Doc Update Link: n/a

## Summary
### Customer Question
After a previous issue with their aws ebs csi driver, the worker, gitserver, and symbols pods were unstable and stuck in a crash loop. 
### Application Engineer Answer
Checking logs showed that the frontend was unhealthy which lead the three pods above to crash. Also failed liveness and readiness probes:
<br />For gitserver the error `Warning  Unhealthy               22m (x37 over 47m)     kubelet                  Liveness probe failed: dial tcp 10.123.88.240:3178: connect: connection refused`
<br />For symbols `Warning  Unhealthy  47m (x3 over 48m)      kubelet            Liveness probe failed: Get "http://10.123.88.99:3184/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers) | Warning  Unhealthy  9m11s (x239 over 49m)  kubelet            Readiness probe failed: Get "http://10.123.88.99:3184/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)`
<br />For worker: `Warning  Unhealthy  46m (x3 over 47m)     kubelet            Liveness probe failed: Get "http://10.123.89.233:6060/healthz": dial tcp 10.123.89.233:6060: connect: connection refused Warning  Unhealthy  13m (x227 over 48m)   kubelet            Readiness probe failed: Get "http://10.123.89.233:6060/ready": dial tcp 10.123.89.233:6060: connect: connection refused`

We tried increasing `timeoutSeconds` and `initialDelaySeconds` to 60s but this only caused the errors to come in later. Also tried increasing `requests.memory` for gitserver to 8G (was 4G) but this did not work either. 

Examining the frontend logs indicated that this could be related to role-based access control
```
W0308 16:25:04.245508       7 reflector.go:324] k8s.io/client-go@v0.23.1/tools/cache/reflector.go:167: failed to list *v1.StatefulSet: statefulsets.apps "gitserver" is forbidden: User "system:serviceaccount:ns-sourcegraph:sourcegraph-frontend" cannot list resource "statefulsets" in API group "apps" in the namespace "ns-sourcegraph"
E0308 16:25:04.245533       7 reflector.go:138] k8s.io/client-go@v0.23.1/tools/cache/reflector.go:167: Failed to watch *v1.StatefulSet: failed to list *v1.StatefulSet: statefulsets.apps "gitserver" is forbidden: User "system:serviceaccount:ns-sourcegraph:sourcegraph-frontend" cannot list resource "statefulsets" in API group "apps" in the namespace "ns-sourcegraph"
```
When I mentioned to the customer that the rbac could have been created incorrectly, they deleted all resources in their kubernetes cluster after my work hours for the day. They ran this command `kubectl apply -n ns-sourcegraph --prune -l deploy=sourcegraph -f ~/Documents/repos/meli-deploy-sourcegraph/generated-cluster --recursive --validate=false` which should have recreated the RBAC but their rbac files were absent from their `generated-cluster` folder. At this point they also got a dirty database error. They had to manually apply `rbac.authorization.k8s.io_v1_role_sourcegraph-frontend.yaml` and `rbac.authorization.k8s.io_v1_rolebinding_sourcegraph-frontend.yaml` (files in github issue). 

The events after implementing this change indicated that some of the pods were still unhealthy but they removed volumes and reapplied and then it worked. Dirty database error was gone without having to go through the steps in our doc. They were able to get to the login page for sourcegraph. 

### Relevant Docs Pages Used/Created
https://docs.sourcegraph.com/admin/how-to/dirty_database

<!-- Once complete, upload a copy to https://github.com/sourcegraph/support-tools-internal/tree/main/resolved-tickets as a .md file -->
<!-- Name the file 6669.md -->
